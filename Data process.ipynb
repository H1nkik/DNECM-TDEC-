{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d103d116",
   "metadata": {},
   "source": [
    "# 20newsgroup subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d66d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "t0 = time()\n",
    "X_tfidf = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")\n",
    "\n",
    "data = X_tfidf.todense()\n",
    "labels +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c4942",
   "metadata": {},
   "source": [
    "## Olivetti_face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ecd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "olive = fetch_olivetti_faces(return_X_y=True)\n",
    "data = olive[0]\n",
    "labels = olive[1]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940633b",
   "metadata": {},
   "source": [
    "## RCV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8000a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "import numpy as np\n",
    "from scipy import ndimage \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91226404",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1 = fetch_rcv1(subset='train', download_if_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f390b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rcv1.data.todense() \n",
    "labels = rcv1.target.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f83914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_matrix_operation(data,matrix_labels):\n",
    "    # row and column\n",
    "    \n",
    "    c = matrix_labels.shape[1] \n",
    "    \n",
    "    #row with single label\n",
    "    \n",
    "    row_sums = np.sum(matrix_labels, axis=1)\n",
    "    ones_rows_indices = np.where(row_sums == 1)[0]\n",
    "\n",
    "    #new matrix\n",
    "    new_matrix = matrix_labels[ones_rows_indices]\n",
    "    \n",
    "    #find corresponding data\n",
    "    new_data = data[ones_rows_indices]\n",
    "    \n",
    "    n = new_matrix.shape[0]\n",
    "    labels = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        index = np.argmax(matrix_labels[i],axis=1) + 1\n",
    "        labels[i]=index\n",
    "    return new_data, labels\n",
    "\n",
    "\n",
    "data,labels = labels_matrix_operation(data,labels) #31 clusters\n",
    "\n",
    "#labels order: 1~c\n",
    "unique_values = set(labels)\n",
    "mapping = {value: index + 1 for index, value in enumerate(sorted(unique_values))}\n",
    "labels = np.vectorize(lambda x: mapping[x])(labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
